{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(r'.env')\n",
    "import os\n",
    "data_dir = os.environ.get('DATA_DIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_dir + \"/sign_mnist_train.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, split_ratio=0.8):\n",
    "    \"\"\"Permet de separer les données en jeux d'entrainement et de validation selon un pourcentage pour le jeu d'entrainement\"\"\"\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "    split_index = int(len(dataset) * split_ratio)\n",
    "\n",
    "    train_set = dataset[:split_index]\n",
    "    validation_set = dataset[split_index:]\n",
    "\n",
    "    return train_set, validation_set\n",
    "\n",
    "\n",
    "train_set, validation_set = split_dataset(np.array(data), split_ratio=0.8)\n",
    "\n",
    "#Division des labels et des données\n",
    "X_train = train_set[:,1:]\n",
    "y_train = train_set[::,0]\n",
    "X_val = validation_set[:,1:]\n",
    "y_val = validation_set[::,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base class for the random forest algorithm\n",
    "class RandomForest():\n",
    "    #initializer\n",
    "    def __init__(self,n_trees=100):\n",
    "        self.n_trees = n_trees\n",
    "        self.trees   = []\n",
    "\n",
    "    #private function to make bootstrap samples\n",
    "    def __make_bootstraps(self,data):\n",
    "        #initialize output dictionary & unique value count\n",
    "        dc   = {}\n",
    "        unip = 0\n",
    "        #get sample size\n",
    "        b_size = data.shape[0]\n",
    "        #get list of row indexes\n",
    "        idx = [i for i in range(b_size)]\n",
    "        #loop through the required number of bootstraps\n",
    "        for b in range(self.n_trees):\n",
    "            #obtain boostrap samples with replacement\n",
    "            sidx   = np.random.choice(idx,replace=True,size=b_size)\n",
    "            b_samp = data[sidx,:]\n",
    "            #compute number of unique values contained in the bootstrap sample\n",
    "            unip  += len(set(sidx))\n",
    "            #obtain out-of-bag samples for the current b\n",
    "            oidx   = list(set(idx) - set(sidx))\n",
    "            o_samp = np.array([])\n",
    "            if oidx:\n",
    "                o_samp = data[oidx,:]\n",
    "            #store results\n",
    "            dc['boot_'+str(b)] = {'boot':b_samp,'test':o_samp}\n",
    "        #return the bootstrap results\n",
    "        return(dc)\n",
    "\n",
    "    #public function to return model parameters\n",
    "    def get_params(self, deep = False):\n",
    "        return {'n_trees':self.n_trees}\n",
    "\n",
    "    #protected function to obtain the right decision tree\n",
    "    #@abstractmethod\n",
    "    def _make_tree_model(self):\n",
    "        pass\n",
    "\n",
    "        #protected function to train the ensemble\n",
    "    def _train(self,X_train,y_train):\n",
    "        #package the input data\n",
    "        training_data = np.concatenate((X_train,y_train.reshape(-1,1)),axis=1)\n",
    "        #make bootstrap samples\n",
    "        dcBoot = self.__make_bootstraps(training_data)\n",
    "        #iterate through each bootstrap sample & fit a model ##\n",
    "        tree_m = self._make_tree_model()\n",
    "        dcOob    = {}\n",
    "        for b in dcBoot:\n",
    "            #make a clone of the model\n",
    "            model = clone(tree_m)\n",
    "            #fit a decision tree model to the current sample\n",
    "            model.fit(dcBoot[b]['boot'][:,:-1],dcBoot[b]['boot'][:,-1].reshape(-1, 1))\n",
    "            #append the fitted model\n",
    "            self.trees.append(model)\n",
    "            #store the out-of-bag test set for the current bootstrap\n",
    "            if dcBoot[b]['test'].size:\n",
    "                dcOob[b] = dcBoot[b]['test']\n",
    "            else:\n",
    "                dcOob[b] = np.array([])\n",
    "        #return the oob data set\n",
    "        return(dcOob)\n",
    "\n",
    "    #protected function to predict from the ensemble\n",
    "    def _predict(self,X):\n",
    "        #check we've fit the ensemble\n",
    "        if not self.trees:\n",
    "            print('You must train the ensemble before making predictions!')\n",
    "            return(None)\n",
    "        #loop through each fitted model\n",
    "        predictions = []\n",
    "        for m in self.trees:\n",
    "            #make predictions on the input X\n",
    "            yp = m.predict(X)\n",
    "            #append predictions to storage list\n",
    "            predictions.append(yp.reshape(-1,1))\n",
    "        #compute the ensemble prediction\n",
    "        ypred = np.mean(np.concatenate(predictions,axis=1),axis=1)\n",
    "        #return the prediction\n",
    "        return(ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for random forest classifier\n",
    "class RandomForestClassifier(RandomForest):\n",
    "    \n",
    "    def __init__(self,n_trees=100,max_depth=None,min_samples_split=2,loss='gini',balance_class_weights=False):\n",
    "        super().__init__(n_trees)\n",
    "        self.max_depth             = max_depth\n",
    "        self.min_samples_split     = min_samples_split\n",
    "        self.loss                  = loss\n",
    "        self.balance_class_weights = balance_class_weights\n",
    "\n",
    "\n",
    "    def calculate_entropy(data):\n",
    "    \n",
    "        label_column = data[:, 0]\n",
    "        _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "        probabilities = counts / counts.sum()\n",
    "        entropy = sum(probabilities * -np.log2(probabilities))\n",
    "        \n",
    "        return entropy\n",
    "\n",
    "    def calculate_overall_entropy(data_below, data_above):\n",
    "    \n",
    "        n = len(data_below) + len(data_above)\n",
    "        p_data_below = len(data_below) / n\n",
    "        p_data_above = len(data_above) / n\n",
    "\n",
    "        overall_entropy =  (p_data_below * self.calculate_entropy(data_below) \n",
    "                        + p_data_above * self.calculate_entropy(data_above))\n",
    "        \n",
    "        return overall_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04279730468038609"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions, y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('ift6758')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76f24fe593248544fb53c45860141e2f5868563163d477b8bfa09ccbbd1149dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
