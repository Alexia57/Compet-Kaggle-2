{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(r'.env')\n",
    "import os\n",
    "data_dir = os.environ.get('DATA_DIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_dir + \"/sign_mnist_train.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, split_ratio=0.8):\n",
    "    \"\"\"Permet de separer les données en jeux d'entrainement et de validation selon un pourcentage pour le jeu d'entrainement\"\"\"\n",
    "\n",
    "    random.shuffle(dataset)\n",
    "\n",
    "    split_index = int(len(dataset) * split_ratio)\n",
    "\n",
    "    train_set = dataset[:split_index]\n",
    "    validation_set = dataset[split_index:]\n",
    "\n",
    "    return train_set, validation_set\n",
    "\n",
    "\n",
    "train_set, validation_set = split_dataset(np.array(data), split_ratio=0.8)\n",
    "\n",
    "#Division des labels et des données\n",
    "X_train = train_set[:,1:]\n",
    "y_train = train_set[::,0]\n",
    "X_val = validation_set[:,1:]\n",
    "y_val = validation_set[::,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(criterion='entropy', max_depth=15)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(max_depth=15, criterion=\"entropy\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=15)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8978328173374613"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_val)\n",
    "(pred == y_val).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_majority_class(labels):\n",
    "    # return the most common label\n",
    "    \n",
    "    counts = Counter(labels)\n",
    "    return counts.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "#def compute_entropy(labels):\n",
    "#    # compute the entropy\n",
    "#    #= sum_l(-p_l log2 (p_l)) for each label l)\n",
    "#    # of the input array.\n",
    "#\n",
    "#    counts = Counter(labels)\n",
    "#    counts = np.array([counts[key] for key in counts])\n",
    "#    freq = counts/counts.sum()\n",
    "#    entropy = -(freq*np.log2(freq)).sum()\n",
    "#    return entropy\n",
    "\n",
    "def compute_entropy(labels):\n",
    "    value_counts = np.bincount(labels)\n",
    "    probabilities = value_counts[value_counts > 0] / len(labels)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1.9219280948873623\n"
     ]
    }
   ],
   "source": [
    "example_labels = np.array([3,1,2,0,2])\n",
    "print(get_majority_class(example_labels)) # should be 2\n",
    "print(compute_entropy(example_labels)) # should be 1.9219280948873623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self):\n",
    "        self.threshold = None\n",
    "        self.col = None\n",
    "        self.is_leaf = None\n",
    "        self.output_class = None\n",
    "        self.left_child=None\n",
    "        self.right_child=None\n",
    "\n",
    "    def find_best_question(self, x, y):\n",
    "        # x: np array of shape (number of examples, number of features)\n",
    "        # y: np array of shape (number of examples,)\n",
    "\n",
    "        best_col = 0\n",
    "        best_val = 0\n",
    "        best_loss = np.inf\n",
    "\n",
    "        num_cols = x.shape[1]\n",
    "        valid_cols = np.arange(num_cols) # nb of features\n",
    "        for col in valid_cols:\n",
    "            # Compute the midpoints of this column's values\n",
    "            sorted_indices = x[:, col].argsort()\n",
    "            sorted_vals = x[sorted_indices, col]\n",
    "            midpoints = [(sorted_vals[i]+sorted_vals[i+1])/2 for i in range(len(sorted_vals)-1)]\n",
    "\n",
    "            for val in midpoints:\n",
    "                # Using col and val, split the labels\n",
    "                # into left_labels, right_labels here\n",
    "\n",
    "                right_subset_rows = x[: , col] > val\n",
    "                left_subset_rows = np.invert(right_subset_rows)\n",
    "\n",
    "                right_labels = y[right_subset_rows]\n",
    "                left_labels = y[left_subset_rows]\n",
    "\n",
    "                right_entropy = compute_entropy(right_labels)\n",
    "                left_entropy = compute_entropy(left_labels)\n",
    "\n",
    "                p_right = len(right_labels)/len(y)\n",
    "                p_left = len(left_labels)/len(y)\n",
    "\n",
    "\n",
    "                loss =  p_left*left_entropy + p_right*right_entropy\n",
    "\n",
    "\n",
    "                if right_labels.shape[0] == 0 or left_labels.shape[0] == 0:\n",
    "                    continue\n",
    "\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_col = col\n",
    "                    best_val = val\n",
    "\n",
    "        self.col = best_col\n",
    "        self.threshold = best_val\n",
    "\n",
    "    def ask_question(self, x):\n",
    "        if not self.is_leaf:\n",
    "            return x[:, self.col] > self.threshold\n",
    "        else:\n",
    "            print(\"Error: leaf nodes cannot ask questions!\")\n",
    "            return False\n",
    "\n",
    "    def predict(self):\n",
    "        if self.is_leaf:\n",
    "            return self.output_class\n",
    "        else:\n",
    "            print(\"Error: non-leaf nodes cannot make a prediction!\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045000000000000005\n",
      "1\n",
      "[False False]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "node=Node()\n",
    "example_x = np.array([[-2.32,  2.02,  0.53,  0.34],\n",
    "       [-1.44,  1.36,  0.12, -0.44],\n",
    "       [-0.28, -0.08,  0.9 , -1.63],\n",
    "       [-0.09,  0.17, -0.28,  0.44],\n",
    "       [ 0.8 , -1.65,  1.36,  1.62]])\n",
    "example_y = np.array([3,1,2,0,2])\n",
    "\n",
    "# Test find_best_question()\n",
    "node.find_best_question(example_x, example_y)\n",
    "print(node.threshold) # should be 0.045\n",
    "print(node.col) # should be 0\n",
    "\n",
    "# Test ask_question()\n",
    "test_x = np.array([[ 1.05, -1.85, -2.24,  1.45],\n",
    "       [ 1.2 , -0.34,  1.54, -0.39]])\n",
    "print(node.ask_question(test_x)) # should be [False False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, max_depth=1):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def create_node(self, x_subset, y_subset, depth):\n",
    "        # Recursive function\n",
    "        node = Node()\n",
    "\n",
    "        majority_class = get_majority_class(y_subset)\n",
    "        majority_class_count = (y_subset == majority_class).sum()\n",
    "        perfectly_classified = majority_class_count == len(y_subset)\n",
    "\n",
    "        if perfectly_classified or depth == self.max_depth:\n",
    "            node.output_class = majority_class\n",
    "            node.is_leaf = True\n",
    "        else:\n",
    "            node.find_best_question(x_subset,y_subset)\n",
    "            node.is_leaf = False\n",
    "            right_subset_rows = node.ask_question(x_subset)\n",
    "            left_subset_rows = np.invert(right_subset_rows)\n",
    "            \n",
    "            # Recursion: create node.left_child and node.right_child \n",
    "            node.left_child = self.create_node(x_subset[left_subset_rows],y_subset[left_subset_rows],depth+1) # FILL IN HERE\n",
    "            node.right_child = self.create_node(x_subset[right_subset_rows],y_subset[right_subset_rows], depth+1) # FILL IN HERE\n",
    "\n",
    "        return node\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.root_node = self.create_node(x,y,depth=1)\n",
    "\n",
    "    def predict(self, x):\n",
    "        predictions = []\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            current_node = self.root_node\n",
    "            x_i = x[i].reshape(1,-1)\n",
    "            done_descending_tree = False\n",
    "            while not done_descending_tree:\n",
    "                if current_node.is_leaf:\n",
    "                    predictions.append(current_node.predict())\n",
    "                    done_descending_tree = True\n",
    "\n",
    "                else:\n",
    "                    if current_node.ask_question(x_i):\n",
    "                        current_node = current_node.right_child\n",
    "                    else:\n",
    "                        current_node = current_node.left_child\n",
    "\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "class Node():\n",
    "    def __init__(self):\n",
    "        self.threshold = None\n",
    "        self.col = None\n",
    "        self.is_leaf = None\n",
    "        self.output_class = None\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "\n",
    "    def find_best_question(self, x, y):\n",
    "        best_col = 0\n",
    "        best_val = 0\n",
    "        best_loss = np.inf\n",
    "\n",
    "        num_cols = x.shape[1]\n",
    "        valid_cols = np.arange(num_cols)\n",
    "        for col in valid_cols:\n",
    "            if issparse(x):\n",
    "                col_values = np.unique(x[:, col].data)\n",
    "            else:\n",
    "                col_values = np.unique(x[:, col])\n",
    "\n",
    "            midpoints = (col_values[:-1] + col_values[1:]) / 2\n",
    "\n",
    "            for val in midpoints:\n",
    "                right_subset_rows = x[:, col] > val\n",
    "                left_subset_rows = ~right_subset_rows\n",
    "\n",
    "                right_labels = y[right_subset_rows]\n",
    "                left_labels = y[left_subset_rows]\n",
    "\n",
    "                right_entropy = compute_entropy(right_labels)\n",
    "                left_entropy = compute_entropy(left_labels)\n",
    "\n",
    "                p_right = len(right_labels) / len(y)\n",
    "                p_left = len(left_labels) / len(y)\n",
    "\n",
    "                loss = p_left * left_entropy + p_right * right_entropy\n",
    "\n",
    "                if right_labels.shape[0] == 0 or left_labels.shape[0] == 0:\n",
    "                    continue\n",
    "\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_col = col\n",
    "                    best_val = val\n",
    "\n",
    "        self.col = best_col\n",
    "        self.threshold = best_val\n",
    "\n",
    "    def ask_question(self, x):\n",
    "        if not self.is_leaf:\n",
    "            return x[:, self.col] > self.threshold\n",
    "        else:\n",
    "            print(\"Error: leaf nodes cannot ask questions!\")\n",
    "            return False\n",
    "\n",
    "    def predict(self):\n",
    "        if self.is_leaf:\n",
    "            return self.output_class\n",
    "        else:\n",
    "            print(\"Error: non-leaf nodes cannot make a prediction!\")\n",
    "            return None\n",
    "\n",
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, max_depth=1):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def create_node(self, x_subset, y_subset, depth):\n",
    "        node = Node()\n",
    "\n",
    "        majority_class = get_majority_class(y_subset)\n",
    "        majority_class_count = np.sum(y_subset == majority_class)\n",
    "        perfectly_classified = majority_class_count == len(y_subset)\n",
    "\n",
    "        if perfectly_classified or depth == self.max_depth:\n",
    "            node.output_class = majority_class\n",
    "            node.is_leaf = True\n",
    "        else:\n",
    "            node.find_best_question(x_subset, y_subset)\n",
    "            node.is_leaf = False\n",
    "            right_subset_rows = node.ask_question(x_subset)\n",
    "            left_subset_rows = ~right_subset_rows\n",
    "\n",
    "            node.left_child = self.create_node(x_subset[left_subset_rows], y_subset[left_subset_rows], depth + 1)\n",
    "            node.right_child = self.create_node(x_subset[right_subset_rows], y_subset[right_subset_rows], depth + 1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        if issparse(x):\n",
    "            x = x.toarray()\n",
    "\n",
    "        self.root_node = self.create_node(x, y, depth=1)\n",
    "\n",
    "    def predict(self, x):\n",
    "        predictions = []\n",
    "\n",
    "        if issparse(x):\n",
    "            x = x.toarray()\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            current_node = self.root_node\n",
    "            x_i = x[i].reshape(1, -1)\n",
    "            done_descending_tree = False\n",
    "            while not done_descending_tree:\n",
    "                if current_node.is_leaf:\n",
    "                    predictions.append(current_node.predict())\n",
    "                    done_descending_tree = True\n",
    "                else:\n",
    "                    if current_node.ask_question(x_i):\n",
    "                        current_node = current_node.right_child\n",
    "                    else:\n",
    "                        current_node = current_node.left_child\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Reste du code inchangé...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=6)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"accuracy: \", (tree.predict(X_val) == y_val).mean() * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class RandomForestClassifier():\n",
    "    def __init__(self, n_estimators=2, max_depth=5, bootstrap_fraction=0.5, features_fraction=0.5):\n",
    "        self.max_depth = max_depth\n",
    "        self.n_estimators = n_estimators\n",
    "        self.bootstrap_fraction = bootstrap_fraction\n",
    "        self.features_fraction= features_fraction\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        num_rows = math.ceil(self.bootstrap_fraction * x.shape[0])\n",
    "        num_cols = math.ceil(self.features_fraction * x.shape[1])\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Create noisy subsets x_subset, y_subset\n",
    "            rows_idx = np.random.choice(x.shape[0], size = num_rows) # FILL IN HERE\n",
    "            cols_idx = np.random.choice(x.shape[1], size = num_cols, replace = False) # FILL IN HERE\n",
    "            x_subset = x[rows_idx][:, cols_idx]\n",
    "            y_subset = y[rows_idx]\n",
    "\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            tree.fit(x_subset, y_subset)\n",
    "            self.estimators.append((tree,cols_idx))\n",
    "\n",
    "    def predict(self, x):\n",
    "        allpreds = np.array([e.predict(x[:,cols]) for e, cols in self.estimators])\n",
    "        predictions = np.array([get_majority_class(y) for y in allpreds.T])\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_counts = []\n",
    "accuracies = []\n",
    "for tree_count in range(1, 20):\n",
    "    model = RandomForestClassifier(n_estimators=tree_count,\n",
    "                                   max_depth=3,\n",
    "                                   bootstrap_fraction=1,\n",
    "                                   features_fraction=0.5)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = (model.predict(X_val) == y_val).mean()\n",
    "    accuracies.append(accuracy)\n",
    "    tree_counts.append(tree_count)\n",
    "\n",
    "print(\"Best performance: \", max(accuracies))\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Performance on test set')\n",
    "plt.plot(tree_counts, accuracies)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('ift6758')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76f24fe593248544fb53c45860141e2f5868563163d477b8bfa09ccbbd1149dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
